# -*- coding: utf-8 -*-
"""ETL project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1duW2jGyaCRYj5LLzwmylbYdyhYbpZhwn

ETL process that:
* extracts data from multiple .csv, .json and scrapes .xml files
* makes minor transformations
* loads data to .csv file
* saves logs in .txt file
"""

import glob                         
import pandas as pd                 
import xml.etree.ElementTree as ET  
from datetime import datetime

# downloads zip file and unzips it
!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/source.zip
!unzip source.zip

# sets paths
logfile = 'logs.txt'                   #file storing logs data
targetfile = 'transformed_data.csv'    #file storing transormed data

"""####Extract

##### Extracting function (CSV)
"""

def extract_csv(file_to_process):
  df = pd.read_csv(file_to_process)
  return df

"""##### Extracting function (JSON)"""

def extract_json(file_to_process):
  df = pd.read_json(file_to_process,lines = True)
  return df

"""##### Extracting function (XML)"""

def extract_xml(file_to_process):
  df = pd.DataFrame(columns=['name','height','weight'])    #empty df with specified column names
  tree = ET.parse(file_to_process)                          #parsing xml file
  root = tree.getroot()                                     #root of xml fime
  for person in root:                                       # loop to go through all branches
    name = person.find('name').text                         # stores name data from a branch 
    height = float(person.find('height').text)
    weight = float(person.find('height').text)
    df = df.append({'name':name,'height':height,'weight':weight}, ignore_index = True)
  return df

"""#####Extract"""

def extract():
  extracted_data = pd.DataFrame(columns=['name','height','weight'])
  for csv_file in glob.glob('*.csv'):                      #processing all csv
    extracted_data = extracted_data.append(extract_csv(csv_file), ignore_index=True)
  for json_file in glob.glob('*.json'):                     #processing all json
    extracted_data = extracted_data.append(extract_json(json_file), ignore_index=True)
  for xml_file in glob.glob('*.xml'):                      #processing all xml
    extracted_data = extracted_data.append(extract_xml(xml_file), ignore_index=True)
    
  return extracted_data

"""####Transform
1.  Convert height which is in inches to millimeters
2.  Convert weight which is in pounds to kilograms
"""

def transform(data):
  data['height'] = round(data.height * 0.0254,2)
  data['weight'] = round(data.weight * 0.45359237,2)
  return data

"""#### Load"""

def load(targetfile,data_to_load):      #loads to csv
  data_to_load.to_csv(targetfile)

"""#### Log"""

def log(message):
  timestamp_format = '%Y-%m-%d %H:%M:%S'             
  now = datetime.now()          
  timestamp = now.strftime(timestamp_format)    # converts present time to text and fits it into defined format
  with open(logfile,'a') as f:
    f.write(timestamp + ' ' + message + '\n')    # creates info lines for log and appends it to log file

"""####ETL"""

log('ETL Job Started')
log('Extraction Started')
extracted_data = extract()
log('Extraction Ended')
extracted_data

log('Transformation Started')
transformed_data = transform(extracted_data)
log('Transformation Ended')
transformed_data

log('Loading Started')
load(targetfile, transformed_data)
log('Loading Ended')
log('ETL Job Ended')



