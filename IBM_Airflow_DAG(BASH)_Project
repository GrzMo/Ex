# importing libraries
from airflow import DAG
from airflow.operators.bash_operator import BashOperator
from airflow.utils.dates import days_ago
from datetime import timedelta

# defining default arguments
default_args = {
     "owner": "JoeDoe"
    ,"start_date" : days_ago(0)
    ,"email" : "JoeDoe@some.com"
    ,"email_on_failure" : True
    ,"email_on_retry" : True
    ,"retries" : 1
    ,"retry_delay" : timedelta(minutes=5),
}

# defining DAG
dag = DAG(
     dag_id = "ETL_toll_data"
    ,description="Apache Airflow Final Assignment"
    ,default_args=default_args
    ,schedule_interval = timedelta(days=1),
)

# creating tasks


unzip_data =  BashOperator(
     task_id = "unzip_data"
    ,bash_command = 'tar zxvf /home/project/airflow/dags/finalassignment/tolldata.tgz -C /home/project/airflow/dags/finalassignment/staging' 
    ,dag=dag,
)

extract_data_from_csv = BashOperator(
     task_id = "extract_data_from_csv"
    ,cwd = '/home/project/airflow/dags/finalassignment/staging'
    ,bash_command = 'cut -d"," -f1-4  vehicle-data.csv > csv_data.csv'
    ,dag=dag,
)

extract_data_from_tsv = BashOperator(
     task_id = "extract_data_from_tsv"
    ,cwd = '/home/project/airflow/dags/finalassignment/staging'
    ,bash_command = 'cut -f5-7  tollplaza-data.tsv | tr "\t" "," > tsv_data.csv'
    ,dag=dag,
)

extract_data_from_fixed_width = BashOperator(
     task_id = "extract_data_from_fixed_width"
    ,cwd = '/home/project/airflow/dags/finalassignment/staging'
    ,bash_command = 'cut -c59-  payment-data.txt | tr " " "," > fixed_width_data.csv'
    ,dag=dag,
)

consolidate_data = BashOperator(
     task_id = "consolidate_data"
    ,cwd = '/home/project/airflow/dags/finalassignment/staging'
    ,bash_command = 'paste -d"," csv_data.csv tsv_data.csv fixed_width_data.csv > extracted_data.csv'
    ,dag=dag,
)

transform_data = BashOperator(
     task_id = "consolidate_data.jpg"
    ,cwd = '/home/project/airflow/dags/finalassignment/staging'
    ,bash_command = 'tr "[a-z]" "[A-Z]" < extracted_data.csv > transformed_data.csv'
    ,dag=dag,
)

# creating pipeline
unzip_data >> extract_data_from_csv >> extract_data_from_tsv >> extract_data_from_fixed_width >> consolidate_data >> transform_data
